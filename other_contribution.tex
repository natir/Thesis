\documentclass[main.tex]{subfiles}

\begin{document}

\chapter{Other contribution} \label{chapter:other_contribution}

This chapter have not any link to other ones they presents about my contribution on some projects where I spent some time during my PhD without sufficiently large contribution to have a specific chapter.

\section{Labsquare}

Labsquare is a community for genomics software, this community was create by me and some other bioinformaticien's friend I participate in developpement of two tools.

\newcommand{\fastqt}{\toolsname{FastQt}}
\newcommand{\cutevariant}{\toolsname{CuteVariant}}

\paragraph{\fastqt} is a rewrite of \toolsname{FastQC} in C++ with the framework \toolsname{Qt}. \fastqt is a tool to check the quality of sequencing data by providing some statistics, GC\% distribution, read length distribution, error rate repartition along the length of reads. At the moment \fastqt development was stopped.

\paragraph{CuteVariant} is a tool to visualize and analyze \toolsname{VCF} (for Variant Call Format) files, these file store variants found between an individual or a dataset of reads against a reference genome. \cutevariant allows selecting annotation, genotype, filter variant, sort and group variants, set operation between VCF file. To perform all this operation a query language was create the \abreviation{VQL} (for Variant Query Language),
\cutevariant is still in development and it was the subject of a poster during the conference Jobim 2019.

\section{CAMI challenge 2}

\abreviation{CAMI} challenge is a metagenomics assembly challenge, I participate in the second edition of CAMI challenge with Camille Marchet, Antoine Limaset, Pierre Peterlongo, Claire Lemaitre and Rayan Chikhi. We tried different strategies to perform an assembly of metagenomics datasets.

\subsection{Dataset description}

In this challenge, we have two datasets with similar reads composition. A set of Illumina Hiseq like reads and a set of Pacbio like reads, simulated by \toolsname{CAMISIM}\cite{camisim}.

We have two datasets, Marine Dataset built to correspond to the composition of a metagenomics sequencing of seawater, and Strain Madness Dataset with very important strain-level variation.

\subsection{Assembly strategy}

On the first hand we perform a short reads assembly with \toolsname{gatb-pipeline} \footnote{https://github.com/GATB/gatb-minia-pipeline}, that is a multi-kmer size short read assembly based on \toolsname{Bloocoo} \cite{bloocoo} for read correction, \toolsname{Minia 3} \cite{minia, bcalm} for contig assembly and \toolsname{BESST} for scaffolding \cite{besst1, besst2, besst3}.

On the second hand, my main contribution in this challenge, we build a long-read assembly pipeline with \toolsname{fmlrc} \cite{fmlrc} a hybrid long-read corrector, and assembly of corrected long read with a pipeline \minimap, \fpa (no internal match and overlap lower than 2000 bases), \miniasm or a \wtdbg assembly. We try to perform read classification before correction and assembly with \toolsname{centrifuge}\cite{centrifuge} to avoid the complexity of metagenomics dataset because our correction assembly tools are not built to use this type of data, but we did not use this strategy due to lack of time.

Finally, we submit a reconciliation of short reads assembly made by \toolsname{gatb-pipeline} and \wtdbg assembly of corrected long-read, if a short reads contig maps in a long reads contig the short reads contigs is discarded. This strategy should have allowed us to have good quality contigs (from long reads assemblies) on the most present strains without losing the information of the least present strains (contained in the short reads contigs). Indeed, long reads sequencing technologies have lower sequencing depths which cannot allow the detection and assembly of the least present strains.

When writing this document, we do not have yet the result  of other teams or an idea of quality of our assembly.

\section{10X linked-read deconvolution} \label{section:other_contribution:10x}

10X linked-read sequencing is a sequencing technique developed by 10X genomics. Figure \ref{fig:other_contribution:10x} presents the main idea of 10X linked-read sequencing. After purificationn DNA is fragmented into large molecules ($\approx$100 kb length). By microfluidic method each large molecule is separated into an individuals bubble. Each bubble is associated to a barcode. In a bubble DNA is fragmented into shorter fragments (compatible with Illumina sequencing method) and a barcode is added to the extremity of each fragment. After a classic short-read sequencing, we can use barcode information to determinate if read comes from the same large fragment or not.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{other_contribution/images/Linked_reads.png}
    \caption{10X linked-read sequencing idea. Source: \url{https://ucdavis-bioinformatics-training.github.io/2018-Dec-Genome-Assembly/10x-supernova/10x-supernova.html}}
    \label{fig:other_contribution:10x}
\end{figure}

Unfortunately, there is not a barcode for each large DNA molecule and therefore several fragments will share the barcode. The task of assigning each reads its original molecule is called \textbf{deconvolution}. Knowing exactly the original molecule of each reads is useful to: 
\begin{itemize}
    \item assembly and scaffolding, by allowing to solve repetitions that are spanned by large molecules,
    \item variant phasing; all reads coming from same molecule necessarily come from the same haplotype.
\end{itemize}
 
If we have access to a good genome reference, deconvolution is easy: by mapping reads against the reference, we can look for reads of same barcode that map within approximately a 100 kb range on the reference genome. Those reads then likely come from same molecule. This general idea used by \toolsname{ema}\cite{ema} and \toolsname{Lariat}\cite{lariat} to assign a read to a molecule.

But when we don't have a good reference genome we cannot use this method. 
%To solve this problem, in collaboration with Chen Sun, Rayan Chikhi , Paul Medvedev and Yoann Dufresne, we try to propose some different techniques to perform a 10x linked-reads deconvolution. 
I proposed a method to perform deconvolution based on assembly graph analysis.
After a classic \DBG assembly (using \toolsname{bcalm}), we remap reads against contigs with the  \toolsname{ema} software. Reads with same barcode and map on same contig are assigned an identical premolecule identifier by \toolsname{ema}. We attempted to glue clusters of reads by analyzing the contigs graph. For all clusters of premolecules with the same barcode, we searched for the shortest path in the contigs graph between clusters. If the length (in number of bases) of a path is shorter than a threshold, we merge both premolecule clusters. 
%This method perform some result, but we didn't have time to finish and evaluate methods.

At this stage, we did not perform a complete evaluation of the method, thus this is still work in progress.

\end{document}